{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG src=\"figures/logo-esi-sba.png\" WIDTH=300 height=\"100\" ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Practical Trainining Series on Software Engineering For Data Science  \n",
    "*By Dr. Belkacem KHALDI (b.khaldi@esi-sba.dz)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Notebook 6: Data Processing & Cleaning for Data Science: Data Wrangling Documents and Web Scraping\n",
    "\n",
    "The purpose of this [Jupyter Notebook] is to getting you introduced to the Data Processing & Cleaning for Data\n",
    "Science: Data Wrangling Documents and Web Scraping. It provides a set of practical Training challenges that allow grasping the different concepts presented in  lecture 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing and Processing Text Documents\n",
    "\n",
    "### Challenge 1: \n",
    "Given the text shown in the code below, you are asked to do the basic parsing and processing text operations checklist seen in the lecture (Slides 4-9) to provide a basic text analysis report.\n",
    "\n",
    "``` python\n",
    "import string\n",
    "\n",
    "text = \"\"\"\n",
    "Data science incorporates tools from multiple disciplines to gather a data set, process, and derive insights from the data set, extract meaningful data from the set, and interpret it for decision-making purposes. \n",
    "The disciplinary areas that make up the data science field include mining, statistics, machine learning, analytics, and programming.\n",
    "\n",
    "Data mining applies algorithms to the complex data set to reveal patterns that are then used to extract useful and relevant data from the set. \n",
    "Statistical measures or predictive analytics use this extracted data to gauge events that are likely to happen in the future based on what the data shows happened in the past.\n",
    "\n",
    "Machine learning is an artificial intelligence tool that processes mass quantities of data that a human would be unable to process in a lifetime. Machine learning perfects the decision model presented under predictive analytics by matching the likelihood of an event happening to what actually happened at a predicted time.\n",
    "Using analytics, the data analyst collects and processes the structured data from the machine learning stage using algorithms. \n",
    "The analyst interprets, converts, and summarizes the data into a cohesive language that the decision-making team can understand.\n",
    "Data science is applied to practically all contexts and, as the data scientist's role evolves, the field will expand to encompass data architecture, data engineering, and data administration.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "`Hint:`\n",
    "These are some of the basic text analysis operations\n",
    "\n",
    "* Reading & Extracting Texts\n",
    "*  Basic Text Cleaning:\n",
    "    * Removing unnecessary punctuation, tags\n",
    "    * Tokenization\n",
    "    * Removing stop words\n",
    "* Basic words Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data science incorporates tools from multiple disciplines to gather a data set process and derive insights from the data set extract meaningful data from the set and interpret it for decisionmaking purposes \n",
      "The disciplinary areas that make up the data science field include mining  statistics machine learning analytics and programming\n",
      "\n",
      "Data mining applies algorithms to the complex data set to reveal patterns that are then used to extract useful and relevant data from the set \n",
      "Statistical measures or predictive analytics use this extracted data to gauge events that are likely to happen in the future based on what the data shows happened in the past\n",
      "\n",
      "Machine learning is an artificial intelligence tool that processes mass quantities of data that a human would be unable to process in a lifetime Machine learning perfects the decision model presented under predictive analytics by matching the likelihood of an event happening to what actually happened at a predicted time\n",
      "Using analytics the data analyst collects and processes the structured data from the machine learning stage using algorithms \n",
      "The analyst interprets converts and summarizes the data into a cohesive language that the decisionmaking team can understand\n",
      "Data science is applied to practically all contexts and as the data scientists role evolves the field will expand to encompass data architecture data engineering and data administration\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "text = \"\"\"\n",
    "Data science incorporates tools from multiple disciplines to gather a data set, process, and derive insights from the data set, extract meaningful data from the set, and interpret it for decision-making purposes. \n",
    "The disciplinary areas that make up the data science field include mining 9, statistics, machine learning, analytics, and programming.\n",
    "\n",
    "Data mining applies algorithms to the complex data set to reveal patterns that are then used to extract useful and relevant data from the set. \n",
    "Statistical measures or predictive analytics use this extracted data to gauge events that are likely to happen in the future based on what the data shows happened in the past.\n",
    "\n",
    "Machine learning is an artificial intelligence tool that processes mass quantities of data that a human would be unable to process in a lifetime. Machine learning perfects the decision model presented under predictive analytics by matching the likelihood of an event happening to what actually happened at a predicted time.\n",
    "Using analytics, the data analyst collects and processes the structured data from the machine learning stage using algorithms. \n",
    "The analyst interprets, converts, and summarizes the data into a cohesive language that the decision-making team can understand.\n",
    "Data science is applied to practically all contexts and, as the data scientist's role evolves, the field will expand to encompass data architecture, data engineering, and data administration.\n",
    "\"\"\"\n",
    "translator = str.maketrans('', '', string.punctuation + string.digits)\n",
    "text = text.translate(translator)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'science', 'incorporates', 'tools', 'from', 'multiple', 'disciplines', 'to', 'gather', 'a', 'data', 'set', 'process', 'and', 'derive', 'insights', 'from', 'the', 'data', 'set', 'extract', 'meaningful', 'data', 'from', 'the', 'set', 'and', 'interpret', 'it', 'for', 'decisionmaking', 'purposes', 'the', 'disciplinary', 'areas', 'that', 'make', 'up', 'the', 'data', 'science', 'field', 'include', 'mining', 'statistics', 'machine', 'learning', 'analytics', 'and', 'programming', 'data', 'mining', 'applies', 'algorithms', 'to', 'the', 'complex', 'data', 'set', 'to', 'reveal', 'patterns', 'that', 'are', 'then', 'used', 'to', 'extract', 'useful', 'and', 'relevant', 'data', 'from', 'the', 'set', 'statistical', 'measures', 'or', 'predictive', 'analytics', 'use', 'this', 'extracted', 'data', 'to', 'gauge', 'events', 'that', 'are', 'likely', 'to', 'happen', 'in', 'the', 'future', 'based', 'on', 'what', 'the', 'data', 'shows', 'happened', 'in', 'the', 'past', 'machine', 'learning', 'is', 'an', 'artificial', 'intelligence', 'tool', 'that', 'processes', 'mass', 'quantities', 'of', 'data', 'that', 'a', 'human', 'would', 'be', 'unable', 'to', 'process', 'in', 'a', 'lifetime', 'machine', 'learning', 'perfects', 'the', 'decision', 'model', 'presented', 'under', 'predictive', 'analytics', 'by', 'matching', 'the', 'likelihood', 'of', 'an', 'event', 'happening', 'to', 'what', 'actually', 'happened', 'at', 'a', 'predicted', 'time', 'using', 'analytics', 'the', 'data', 'analyst', 'collects', 'and', 'processes', 'the', 'structured', 'data', 'from', 'the', 'machine', 'learning', 'stage', 'using', 'algorithms', 'the', 'analyst', 'interprets', 'converts', 'and', 'summarizes', 'the', 'data', 'into', 'a', 'cohesive', 'language', 'that', 'the', 'decisionmaking', 'team', 'can', 'understand', 'data', 'science', 'is', 'applied', 'to', 'practically', 'all', 'contexts', 'and', 'as', 'the', 'data', 'scientists', 'role', 'evolves', 'the', 'field', 'will', 'expand', 'to', 'encompass', 'data', 'architecture', 'data', 'engineering', 'and', 'data', 'administration']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "tokens = nltk.word_tokenize(text.lower())\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'science', 'incorporates', 'tools', 'multiple', 'disciplines', 'gather', 'data', 'set', 'process', 'derive', 'insights', 'data', 'set', 'extract', 'meaningful', 'data', 'set', 'interpret', 'decisionmaking', 'purposes', 'disciplinary', 'areas', 'make', 'data', 'science', 'field', 'include', 'mining', 'statistics', 'machine', 'learning', 'analytics', 'programming', 'data', 'mining', 'applies', 'algorithms', 'complex', 'data', 'set', 'reveal', 'patterns', 'used', 'extract', 'useful', 'relevant', 'data', 'set', 'statistical', 'measures', 'predictive', 'analytics', 'use', 'extracted', 'data', 'gauge', 'events', 'likely', 'happen', 'future', 'based', 'data', 'shows', 'happened', 'past', 'machine', 'learning', 'artificial', 'intelligence', 'tool', 'processes', 'mass', 'quantities', 'data', 'human', 'would', 'unable', 'process', 'lifetime', 'machine', 'learning', 'perfects', 'decision', 'model', 'presented', 'predictive', 'analytics', 'matching', 'likelihood', 'event', 'happening', 'actually', 'happened', 'predicted', 'time', 'using', 'analytics', 'data', 'analyst', 'collects', 'processes', 'structured', 'data', 'machine', 'learning', 'stage', 'using', 'algorithms', 'analyst', 'interprets', 'converts', 'summarizes', 'data', 'cohesive', 'language', 'decisionmaking', 'team', 'understand', 'data', 'science', 'applied', 'practically', 'contexts', 'data', 'scientists', 'role', 'evolves', 'field', 'expand', 'encompass', 'data', 'architecture', 'data', 'engineering', 'data', 'administration']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "en_stopwords = stopwords.words('english')\n",
    "en_stopwords = set(en_stopwords)\n",
    "tokens = [w for w in tokens if w not in en_stopwords]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2:\n",
    "You've just started a new data science position at the Cybersecurity Unit of the U.S. DEPARTMENT OF COMMERCE. The department wants to build, test, and evaluate new machine learning model using thier 2020 annual report document availabe in the local data folder:`2020_Cybersecurity_and_Privacy_Annual_Re.docx`. \n",
    "\n",
    "You are asked to provide a visual report summarizing the most common frequency keywords used in their report. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping: Parsing and processing Web Pages\n",
    "### Challenge 3:\n",
    "We want to analyse text collected from https://en.wikipedia.org/wiki/Data_science  wikipedia page. We are only interested on the text content of links html anchor (`a`).  \n",
    "\n",
    "1. Do the cheklist basic text analyses to provid a visyal summarry of all href text links available on the page.\n",
    "\n",
    "`Hint:`\n",
    "1. Follow and adjust the procedures in Lecture 6 - Slides: 14-16 - to collect the required text. In case, you have not figured out how to collect the required information, here is below a code that help you:\n",
    "\n",
    "\n",
    "``` python\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import lxml\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Data_science'\n",
    "page = urlopen(url).read().decode('utf-8')\n",
    "\n",
    "soup = bs(page)\n",
    "\n",
    "links = soup.find_all('a')\n",
    "all_link_text = []\n",
    "\n",
    "all_link_text.extend([a.text for a in links])\n",
    "\n",
    "text = ' '.join(all_link_text)\n",
    "text\n",
    "``` \n",
    "\n",
    "2. Follow the checklist text analysis to clean and visualize the most common words used in the collected text.\n",
    "\n",
    "### Challenge 4:\n",
    "We want to analyse text related to data science topic collected from different web pages: https://www.heavy.ai/learn/data-science,  https://en.wikipedia.org/wiki/Data_science, https://www.ibm.com/cloud/learn/data-science-introduction, and https://deepai.org/machine-learning-glossary-and-terms/data-science alongside with the text string object of challenge 01.\n",
    "\n",
    "Note that we are only interested on the text content of  html anchor (`p`) from the webpages.  \n",
    "\n",
    "1. Do the required procedures to collect all  `p` text available on all of the aformentioned web pages.\n",
    "2. Append the collected text with the text string object of challenge 01\n",
    "3. Do the cheklist basic text analyses to provid a visyal summarry of the most frequently used keywords on the resulted text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4:\n",
    "\n",
    "You're in the initial stages of a new position as a Data Scientist at Goodreads (https://www.goodreads.com/) company. Your primary task is to build a robust understanding of customer sentiments and preferences related to quots, focusing on the `Motivational` tag.\n",
    "\n",
    "The team you're collaborating with has a specific interest in quotes text, authors or Book titles, tags, and number of likes  from the `Motivational` tag on Goodreads as shown in the figure. They've tasked you with conducting web scraping and basic text analysis on quotes from this category. Your goal is to provide insights into the most frequently occurring keywords by author, or book title, or keyword tags.\n",
    "\n",
    "\n",
    "<figure>\n",
    "  <IMG src=\"figures/goodbooks.png\"  ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "#### II.  Requirements:\n",
    "\n",
    "##### 1. Web Scraping and data collection:\n",
    "\n",
    "1. Scraping the the required contents from the two following first 5 pages:\n",
    "  *  https://www.goodreads.com/quotes/tag/motivational?page=1\n",
    "  *  https://www.goodreads.com/quotes/tag/motivational?page=2\n",
    "  *  https://www.goodreads.com/quotes/tag/motivational?page=3\n",
    "  *  https://www.goodreads.com/quotes/tag/motivational?page=4\n",
    "  *  https://www.goodreads.com/quotes/tag/motivational?page=5\n",
    "  \n",
    "2. Store the scraped data in a dataframe with the approporiat columns names \n",
    "##### 2. Text Analysis:\n",
    "\n",
    "1. Performing basic text analysis and generate a visulaization report on:\n",
    "  - The overall quot texts of the entire dataframe to identify the most common frequency keywords.\n",
    "  - The quot texts by author or book title, or tag\n",
    "2. Using the apropriate chart type, Visualize the number of likes  by author or booktitle or by tag.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Hints:\n",
    "1- Consider using the Browser Dev. Tools for further assistance and html componenets inspections to identify the appropriat related contents html css classes and tags.For example, each quote detail text is displayed in an html markup `div` with class name: `quoteText`.\n",
    "You may get any `<html_markup_name>` contents for a specific class name by using the following code: \n",
    "``` python\n",
    "soup.find_all(\"<html_markup_name>\", {\"class\": \"<class_name>\"})\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Solution"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
